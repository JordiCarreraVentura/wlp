{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodologies\n",
    "\n",
    "Let's assume we want to create an LNP system that, when it gets linguistic input _X_, reacts with a pre-defined response _Y_. Almost any system we can design will fall in some of the following categories:\n",
    "\n",
    "Type | Input | Comments\n",
    "---|---|---|\n",
    "Fully supervised (rule-based) | Explicit linguistic patterns, _if X then Y_'s, hard-coding, keywords | This system only follows pre-defined behavior, it does not exhibit new behavior. So, it cannot really be considered artificial intelligence, it is rather human intelligence encoded in a program.\n",
    "Supervised | Training instances, usually tuples of the form _(X, Y)_ | _X_ is often normalized/vectorized/transformed in some way so that the system can make sense of it quantitatively.\n",
    "Semi-supervised | Same data as for supervised systems, plus some amount of additional data coming from the system's predictions after training. | Once a system has been trained to return _Y_ as output every time that it gets _X_ as input, and does so with a high-enough level of confidence for new examples, we can keep these new _(X, Y)_ instances and use them to re-train the model as needed (for instance, to account for time-dependent changes in the data, such as in Twitter hashtags for trending topics).\n",
    "Bootstrapped | A set of seeds together with their tags _(X, Y)_, and a large domain-specific corpus to extract matches from. | The system extracts new examples that are most similar to the previous ones (based on the contexts in which they all appear, for instance), and adds them as additional instances with the same tags. In that way, the pool of known _(X, Y)_ available for training can be expanded fairly quickly in a few iterations. It is essentially the same as semi-supervised learning but the learned content is normally not the same as the expected outcome of the system (that is, we want to learn semantic relations to feed into a system but the goal of the system is probably not to simply return semantic relations, which means that we are not using a standard semi-supervised cycle).\n",
    "Distant-(or weakly-)supervised | Same data format as for supervised systems but the _(X, Y)_ pairs do not come from manual annotation but from some heuristics-based annotation. | Instead of tagging 10,000 tweets specifying which ones are about movies and which ones are not, we take a list of movie titles and we tag any tweet containing one of those titles as a tweet being \"about movies\". It may work for a large percentage of the data, but we can expect some issues: many false positives for movie titles like _\"The Thing\"_, many false negatives for partial matches of _\"Harry Potter VI: Harry Potter and the Half-Blood Prince\"_ (just the title is like a whole tweet :D), and movie mentions that are not about movies: _\"That actor from Inception was here yesterday\"_).\n",
    "Unsupervised | Raw data (e.g., stream of plain text) without any annotation. | The system is expected to learn from the data the same as humans would naturally learn from it, without being told explicitly what it is in advance[2].\n",
    "Hybrid | As required by some combination of the previous methods. | Most commonly, (rule-based + bootstrapped), (rule-based + supervised) or (rule-based + semi-supervised).\n",
    "\n",
    "\n",
    "[1] Also called _ground truth lables_ or, more simply, _labels_. Alternative names include: annotation, tags, gold standard, reference corpus.\n",
    "\n",
    "[2] It still sounds a bit like sci-fi but there are already meaningful results for a number of tasks (for instance, Google's word2vec or IBM's Watson)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
