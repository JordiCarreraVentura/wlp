{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodologies\n",
    "\n",
    "Let's assume we want to create an LNP system that, when it gets linguistic input _X_, reacts with a pre-defined response _Y_. Almost any system we can design will fall in some of the following categories:\n",
    "\n",
    "## JORDI: bootstrapping is semi-supervision [FIX!]\n",
    "\n",
    "Type | Input | Comments\n",
    "---|---|---|\n",
    "Fully supervised (rule-based) | Explicit linguistic patterns, _if X then Y_'s, hard-coding, keywords | This system only follows pre-defined behavior, it does not exhibit new behavior. So, it cannot really be considered artificial intelligence, it is rather human intelligence encoded in a program.\n",
    "Supervised | Training instances, usually tuples of the form _(X, Y)_ | _X_ is often normalized/vectorized/transformed in some way so that the system can make sense of it quantitatively.\n",
    "Semi-supervised | Same data as for supervised systems, plus some amount of additional data coming from the system's predictions after training. | Once a system has been trained to return _Y_ as output every time that it gets _X_ as input, and does so with a high-enough level of confidence for new examples, we can keep these new _(X, Y)_ instances and use them to re-train the model as needed (for instance, to account for time-dependent changes in the data, such as in Twitter hashtags for trending topics).\n",
    "Bootstrapped | A set of seeds together with their tags _(X, Y)_, and a large domain-specific corpus to extract matches from. | The system extracts new examples that are most similar to the previous ones (based on the contexts in which they all appear, for instance), and adds them as additional instances with the same tags. In that way, the pool of known _(X, Y)_ available for training can be expanded fairly quickly in a few iterations. It is conceptually very similar to semi-supervised learning but, rather than adding as a new _(x, y)_ instance some previously unseen _x_ for which the trained system's returns _y_, in bootstrapping we ignore the prediction _y_ (and the potential error associated with it) and rely rather on a measure of the similarity of _x_ with respect to previous _X_ (the seeds) using some independent metric. This similarity measure is supposed to be more precise than semi-supervision but can also be expected to yield much sparser results, so bootstrapping may not be possible for many tasks where semi-supervision will still be available.\n",
    "Distant-(or weakly-)supervised | Same data format as for supervised systems but the _(X, Y)_ pairs do not come from manual annotation but from some heuristics-based annotation. | Instead of tagging 10,000 tweets specifying which ones are about movies and which ones are not, we take a list of movie titles and we tag any tweet containing one of those titles as a tweet being \"about movies\". It may work for a large percentage of the data, but we can expect some issues: many false positives for movie titles like _\"The Thing\"_, many false negatives for partial matches of _\"Harry Potter VI: Harry Potter and the Half-Blood Prince\"_ (just the title is like a whole tweet :D), and movie mentions that are not about movies: _\"That actor from Inception was here yesterday\"_).\n",
    "Unsupervised | Raw data (e.g., stream of plain text) without any annotation. | The system is expected to learn from the data the same as humans would naturally learn from it, without being told explicitly what it is in advance[2].\n",
    "Hybrid | As required by some combination of the previous methods. | Most commonly, (rule-based + bootstrapped), (rule-based + supervised) or (rule-based + semi-supervised).\n",
    "\n",
    "\n",
    "[1] Also called _ground truth lables_ or, more simply, _labels_. Alternative names include: annotation, tags, gold standard, reference corpus.\n",
    "\n",
    "[2] It still sounds a bit like sci-fi but there are already meaningful results for a number of tasks (for instance, Google's word2vec or IBM's Watson)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our dataset\n",
    "\n",
    "---Download NTLK---\n",
    "\n",
    "In NLP and Linguistics, another very common name for a dataset is _corpus_. It comes from Latin and it denotes a collection of text or texts grouped based on some criteria and often correlated with some type of annotation (the texts' authors, years of publication, information on their content, etc.) The plural of _corpus_ is _corpora_.\n",
    "\n",
    "\n",
    "## Raw text\n",
    "UMBC\n",
    "\n",
    "\n",
    "## Terminology extraction, distributional modelling and classification\n",
    "\n",
    "### Reuters\n",
    "Motivation (long, doc)\n",
    "\n",
    "### Brown?\n",
    "\n",
    "### Wikipedia Q&A\n",
    "Motivation (short, Q&A, knowledge-oriented)\n",
    "\n",
    "\n",
    "## Sentiment analysis\n",
    "\n",
    "### Crowdflower\n",
    "Motivation\n",
    "Crowdflower's public sentiment analysis dataset\n",
    "\n",
    "### Kaggle\n",
    "\n",
    "\n",
    "\n",
    "## Other types of datasets\n",
    "Word-sense-annotated corpus\n",
    "PoS-tagged annotated corpus\n",
    "STREUSLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
